diag(10)
remove(list=ls())
# Load the necessary packages
library(tidyverse)
# c) all words ending with "ing" or "ise"
str_view(words, "ing$|ise$", match=T)  # Da capire come mettere "or"
library(tidyverse)
library(stringr)
vector <- c("emoticon", ":)", "symbol", "$^$")
writeLines((vector))
# a) string of 3 characters with the letter o in the middle
str_view(vector, ".o.")
# b) expression "emoticon"
str_view(vector, "emoticon")
# or
str_view(vector, "^emoticon$")
# c) expression ":)"
str_view(vector, "\\:\\)")
# or
str_view(vector, "^\\:\\)$")
# d) expression "$^$"
str_view(vector, "\\$\\^\\$")
# or
str_view(vector, "^\\$\\^\\$$")
# or
str_view(vector, "^\\:\\)$")
# d) expression "$^$"
str_view(vector, "\\$\\^\\$")
# or
str_view(vector, "^\\$\\^\\$$")
# -------------------------------------------------#
# 2. Exercise ----
# Corpus of 980 words is given
stringr::words
# -------------------------------------------------#
# 2. Exercise ----
# Corpus of 980 words is given
stringr::words
# a) all words containing the expression "yes" (add the parameter match=T)
str_view(words, "yes", match=T)
# b) all words starting with "w"
str_view(words, "^w", match=T)
# c) all words ending with "x"
str_view(words, "x$", match=T)
# a) all words starting with a vowel
str_view(words, "^[aeiou]", match=T)
# b) all words that start only with a consonant
str_view(words, "^[^aeiou]", match=T)
# c) all words ending with "ing" or "ise"
str_view(words, "ing$|ise$", match=T)  # Da capire come mettere "or"
# d) all words ending with "ed" but not with "eed"
str_view(words, "[^e]ed$", match=T)  # Da capire come non mettere "eed"
# d) all words ending with "ed" but not with "eed"
str_view(words, "ed$", match=T)
str_view(words, "[^e]ed$", match=T)  # Da capire come non mettere "eed"
library(tidyverse)
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
library(stringr)
vector <- c("emoticon", ":)", "symbol", "$^$")
writeLines((vector))
vector <- c("emoticon", ":)", "symbol", "$^$")
writeLines((vector))
# a) string of 3 characters with the letter o in the middle
str_view(vector, ".o.")
# b) expression "emoticon"
str_view(vector, "emoticon")
# a) string of 3 characters with the letter o in the middle
str_view(vector, ".o.")
# b) expression "emoticon"
str_view(vector, "emoticon")
# or
str_view(vector, "^emoticon$")
# c) expression ":)"
str_view(vector, "\\:\\)")
# or
str_view(vector, "^\\:\\)$")
# d) expression "$^$"
str_view(vector, "\\$\\^\\$")
# or
str_view(vector, "^\\$\\^\\$$")
# d) expression "$^$"
str_view(vector, "\\$\\^\\$")
# -------------------------------------------------#
# 2. Exercise ----
# Corpus of 980 words is given
stringr::words
# a) all words containing the expression "yes" (add the parameter match=T)
str_view(words, "yes", match=T)
# b) all words starting with "w"
str_view(words, "^w", match=T)
# c) all words ending with "x"
str_view(words, "x$", match=T)
# -------------------------------------------------#
# 3. Exercise ----
# Corpus of 980 words is given
stringr::words
# a) all words starting with a vowel
str_view(words, "^[aeiou]", match=T)
# b) all words that start only with a consonant
str_view(words, "^[^aeiou]", match=T)
# c) all words ending with "ing" or "ise"
str_view(words, "ing$|ise$", match=T)  # Da capire come mettere "or"
# d) all words ending with "ed" but not with "eed"
str_view(words, "[^e]ed$", match=T)  # Da capire come non mettere "eed"
# install.packages("haven)
library(haven)
laptops <- read_dta("laptops.dta")
# install.packages("haven)
library(haven)
# nice output
install.packages("sjPlot")
install.packages("stargazer")
library(sjPlot)
# install.packages("haven)
check .libPaths()
# install.packages("haven)
check.libPaths()
# install.packages("haven)
.libPaths()
library(haven)
# install.packages("haven)
install.packages("heaven")
?summary
setwd("C:/Users/guder/OneDrive/Michele/Università/Varsavia/Courses/1° Semester/Econometrics/Project/Dataset")
library(moments)
library(dplyr)
library(tseries)
library(epiDisplay)
library(tidyverse)
library(car)
library(lmtest)
library(MASS)
library(olsrr)
library(haven)
library(ggplot2)
library(ggpubr)
rm(list=ls())
data <- read.csv("Dataset_row.csv", header=T)
#View(data)
head(data)
dim(data)
attach(data)
# Check any possible NA in our dataset
any(is.na(data))
# There aren't, ok
# Remove not chosen variables (with the exception of districts)
data <- data[-c(4, 6:62)]
#View(data)
# Adjust some values of "floor" variables
data$floor <- round(data$floor)
#View(data)
# Approximation of the variable "years"
data$year_built <- round(data$year_built, digits = 2)
#View(data)
# Subtraction to get the apartments' age
data$year_built <- 2022 - data$year_built
#View(data)
# Rename columns (we will purposely omit some special characters of the Polish
# alphabet to avoid reading problems)
colnames(data)
names(data)[4] <- "age"
names(data)[5] <- "district_Bemowo"
names(data)[6] <- "district_Bialoleka"
names(data)[7] <- "district_Bielany"
names(data)[8] <- "district_Centrum"
names(data)[9] <- "district_Metro.Wilanowska"
names(data)[10] <- "district_Mokotow"
names(data)[11] <- "district_Ochota"
names(data)[12] <- "district_Praga-Poludnie"
names(data)[13] <- "district_Praga-Polnoc"
names(data)[14] <- "district_Rembertow"
names(data)[15] <- "district_Targowek"
names(data)[16] <- "district_Ursus"
names(data)[17] <- "district_Ursynow"
names(data)[18] <- "district_Warszawa"
names(data)[19] <- "district_Wawer"
names(data)[20] <- "district_Wesola"
names(data)[21] <- "district_Wilanow"
names(data)[22] <- "district_Wola"
names(data)[23] <- "district_Wlochy"
names(data)[24] <- "district_Mazowieckie"
names(data)[25] <- "district_Srodmiescie"
names(data)[26] <- "district_Zoliborz"
#View(data)
# There are some negative values in the column "age" --> we remove them
data <- filter(data, age > 0)
#View(data)
# Remove relevant rows of not chosen districts
data <- filter(data, c(district_Centrum != "1" &
district_Metro.Wilanowska != "1" &
district_Warszawa != "1" &
district_Mazowieckie != "1"))
# Remove not chosen districts
data <- data[-c(8:9, 18, 24)]
#View(data)
# Approximation variable "gross_price" (2 decimal places)
data$gross_price <- round(data$gross_price, 2)
#View(data)
attach(data)
#gather city centre districts and suburbs districts into one dummy variable
#and eliminate all dustricts variables
data <- mutate(data, city_centre =
ifelse(data$district_Mokotow == 1 | data$district_Ochota == 1 |
data$district_Wola ==1 | data$district_Zoliborz==1 | data$district_Srodmiescie==1 |
data$`district_Praga-Polnoc`==1 | `district_Praga-Poludnie`==1,1, 0))
data <- data[-c(5:22)]
attach(data)
#statistical analysis new dummies: city_centre
by(data$gross_price, data$city_centre, summary)
sum(city_centre)
sum(city_centre)/dim(data)[1]
#BEST MODEL
reg_6 <- lm(log(gross_price) ~ area + room_num + area:room_num + floor + log(age) + data$city_centre, data=data)
#RESET test
resettest(reg_6, power = 2:3, type = c("fitted"))
#Normality of residuals
summary(reg_6$residuals)
skewness(reg_6$residuals)
kurtosis(reg_6$residuals)
# Histogram + normal curve
h <- hist(reg_6$residuals, col = "blue", xlab = "Residuals", freq=F, nclass = 50)
xfit <- seq(min(reg_6$residuals), max(reg_6$residuals), length=50)
yfit <- dnorm(xfit, mean=mean(reg_6$residuals), sd=sd(reg_6$residuals))
lines(xfit, yfit, col="red", lwd=2)
# q-q plot for standardized residuals
plot(reg_6, which=2)
res.std <- rstandard(reg_6)
boxplot(res.std)
#tests for Normality yield the rejection of H0
#thus residuals are non-Normal distributed
jarque.bera.test(reg_6$residuals)
shapiro.test(reg_6$residuals)
#HOMOSCEDASTICITY
# Residuals vs fitted - we should have randomly located points
plot(reg_6, which=1)
# Breusch-Pagan test (it yeilds the rejection of H0, thus there is Heteroscedasticity)
#-> H0: homoscedastic residuals
bptest(reg_6, studentize=FALSE)
# robust regression (to solve problem with Heteroscedasticity)
reg_robust <- rlm(log(gross_price) ~ area + room_num + area:room_num + floor + log(age) + data$city_centre, data=data)
summary(reg_robust)
#MULTICOLLINEARITY
#VIF-test results say that no variable should be removed from the model
#given that all results are less than 10 (only area:room_num, but it's normal)
vif(reg_robust)
# residuals
data$resids <- residuals(reg_6)
# leverage
data$lev <- hatvalues(reg_6)
# standardized residuals
data$rstd <- rstandard(reg_6)
# Cook distance
data$cookd <- cooks.distance(reg_6)
# fitted values
data$yhat <- fitted(reg_6)
# For how many observations leverage is > 2k/n?
# threshold = 0.00430372
length(data$lev[data$lev > (2*(length(reg_6$coefficients)/nrow(data)))])
# For how many observations |stand.residuals| >2?
length(data$rstd[abs(data$rstd)>2])
# For how many observation Cook's distance is > 4/n?
# 4/n = 0.00122963
length(data$cookd[data$cookd > 4/nrow(data)])
nontypical <- data[data$lev > 0.00430372 & abs(data$rstd)>2
& data$cookd > 0.00122963, ]
# Cook's distance plot for subsequent observations
# abline -- adds a threshold line
plot(reg_6, which=4, cook.level=(4/nrow(data)))
abline(h=4/nrow(data), lty=2, col= "red")
# Leverage vs standardized residuals
plot(reg_6, which=5)
# or:
ols_plot_resid_lev(reg_6)
# id.method="noteworthy" identifies a couple of suspicious observations
influencePlot(reg_6, id.method="noteworthy",
main="Leverage and residuals",
sub= "Circle size is proportional to Cook D value")
nontypical_numb <- data[c(673, 1070, 1810), c(1:10)]
# COLLINEARITY
ols_vif_tol(reg_6)
